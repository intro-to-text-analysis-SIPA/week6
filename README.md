# Week 6: Principles of text analysis: Cleaning and processing text for analysis with the NLTK library


This week, we will work with the Natural Language Toolkit (NLTK), a suite of Python libraries for processing and manipulating text-data. We will also review the necessary steps for cleaning and processing our text before we can analyze it by essentially converting each word in a text into an individual data point. 

- Topics covered:
    - Working with text-as-data
    - Cleaning and standardizing text data
    - Preparing texts for computational analysis
    - Basic text analysis tools 
- Curriculum for this session:
    - DHRI's [Introduction to Text Analysis with Python and NLTK](https://curriculum.dhinstitutes.org/workshops/text-analysis/) (lessons 1-12)
- Assignments (due by 10am on the day of class):
   - Work through the curriculum for the upcoming week's session in a Jupyter Notebook. Download your Jupyter Notebook as "ipynb" file (Go to "File", "Download as", "Notebook (.ipynb)"), and [upload](https://docs.github.com/en/repositories/working-with-files/managing-files/adding-a-file-to-a-repository) the file to the weekly GitHub assignment link.
        -  You are welcome to use the dataset provided in the curriculum link or use a dataset of your choice. 
- Additional readings/resources (not required, but useful!):
    - Tutorials:
        - Geeks for Geeks: [Generating Word Cloud in Python](https://www.geeksforgeeks.org/generating-word-cloud-python/#:~:text=For%20generating%20word%20cloud%20in,from%20UCI%20Machine%20Learning%20Repository)
    - Explainer:
        - Scribbr: [Textual Analysis | Guide, 3 Approaches & Examples](https://www.scribbr.com/methodology/textual-analysis/)
    - Projects:
        - Digital Humanities at Yale University Library: [Robots Reading Vogue](http://dh.library.yale.edu/projects/vogue/)
        - Boston College Library: [Text and Data Mining Projects](https://libguides.bc.edu/textdatamining/projects)
